#!/usr/bin/env python

import traceback
import rospy
import cv2
from cv_bridge import CvBridge
from sensor_msgs.msg import Image
from std_msgs.msg import Float32, Float32MultiArray, MultiArrayLayout, MultiArrayDimension, String
import numpy as np

from paul_alarm.msg import DualImage

# Significant amounts of code taken from 
# https://pyimagesearch.com/2015/06/01/home-surveillance-and-motion-detection-with-the-raspberry-pi-python-and-opencv/
class MotionDetectorNode:
    def __init__(self):
        self.initialized = False
        rospy.init_node('motion_detector', anonymous=False, xmlrpc_port=45202, tcpros_port=45203)
        self.image_sub = rospy.Subscriber('/camera/image_undistorted', Image, self.image_callback)
        self.result_image_pub = rospy.Publisher('/motion/video', DualImage, queue_size=1)
        self.area_pub = rospy.Publisher('/motion/area', Float32, queue_size=1)
        self.largest_pub = rospy.Publisher('/motion/largest', Float32MultiArray, queue_size=1)
        self.bridge = CvBridge()
        self.bg = None
        self.first_received = False
        self.initialized = True
        rospy.loginfo("Motion Detector Node Initialized")

    def image_callback(self, msg):
        if not self.initialized:
            return
        rospy.loginfo("Detecting motion")
        try:
            # Convert ROS Image message to OpenCV image
            cv_image = self.bridge.imgmsg_to_cv2(msg, "bgr8")
            if not self.first_received:
                rospy.loginfo("First image received for motion detection.")
                self.first_received = True
            # Convert to grayscale
            grayscale = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)
            grayscale = cv2.GaussianBlur(grayscale, (5, 5), 0)
            # Init self.bg, if necessary
            if self.bg is None:
                self.bg = grayscale.copy().astype("float")

            # Find difference with background
            delta = cv2.absdiff(grayscale, self.bg.astype("uint8"))
            # Generate contours
            thresh = cv2.threshold(delta, 5, 255, cv2.THRESH_BINARY)[1]
            thresh = cv2.dilate(thresh, None, iterations=4)
            contours = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
            contours = contours[0]
            cv2.drawContours(cv_image, contours, -1, (0, 255, 0), 2)

            motion_area = 0
            largest_area = 0
            largest_bbox = [0,0,0,0,0]
            for c in contours:
                area = cv2.contourArea(c)
                if area < 400:
                    continue
                motion_area += area
                (x, y, w, h) = cv2.boundingRect(c)
                if area > largest_area:
                    largest_area = area
                    largest_bbox = [x, y, w, h, area]
                cv2.rectangle(cv_image, (x,y), (x+w,y+h), (255,0,255), 2)
                cv2.putText(cv_image, "A: {}".format(area), (x,y+h), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

            self.bg = cv2.accumulateWeighted(grayscale.astype("float"), self.bg, 0.2)

            area_msg = Float32()
            area_msg.data = motion_area
            self.area_pub.publish(area_msg)

            largest_msg = Float32MultiArray()
            largest_msg.layout = MultiArrayLayout()
            d = MultiArrayDimension()
            d.label = "i"
            d.size = 5
            d.stride = 1
            largest_msg.layout.dim = [d]
            largest_msg.layout.data_offset = 0
            largest_msg.data = largest_bbox
            self.largest_pub.publish(largest_msg)

            msg_out = DualImage()
            msg_out.image = self.bridge.cv2_to_imgmsg(cv_image, encoding='bgr8')
            msg_out.image_raw = msg
            self.result_image_pub.publish(msg_out)
        except Exception as e:
            rospy.logerr("Error detecting motion: %s\n%s\n", e, traceback.format_exc())
        

if __name__ == '__main__':
    try:
        node = MotionDetectorNode()
        rospy.spin()
    except rospy.ROSInterruptException:
        pass